# AIProxy 代理服务测试需求文档

## 1. 文档概述

### 1.1 文档目的
本文档旨在为AIProxy代理服务项目提供全面的测试需求规范，确保系统的功能正确性、性能稳定性和安全可靠性。

### 1.2 测试范围
- **集成测试**：代理转发、API-Key替换、渠道集成等
- **兼容性测试**：多渠道API、多协议支持等

### 1.3 测试环境
- **开发环境**：开发人员本地测试
- **测试环境**：独立的测试服务器环境
- **预生产环境**：生产环境的镜像环境

### 1.4 测试工具
- **集成测试**：Python + OpenAI兼容SDK、DashScope SDK、WebSocket客户端库

## 2. 集成测试需求

### 2.1 OpenAI兼容API集成测试

#### 2.1.1 Chat Completions API集成测试
**测试目标**：验证OpenAI Chat Completions API的端到端处理

**测试实现**：使用Python OpenAI SDK进行完整的API调用测试

**测试用例**：
1. **基础聊天完成测试**
   - 测试方法：使用OpenAI SDK调用chat.completions.create()
   - 输入：标准的聊天请求
   - 预期：成功返回AI响应
   - 验证：响应格式符合OpenAI API规范

2. **流式响应测试**
   - 测试方法：使用stream=True参数调用API
   - 输入：流式聊天请求
   - 预期：返回流式响应数据
   - 验证：数据流完整性和格式正确性

#### 2.1.2 多渠道集成测试
**测试用例**：
1. **阿里云百炼集成**
   - 输入：百炼API格式的请求
   - 预期：成功调用百炼API
   - 验证：响应格式符合百炼API规范

2. **OpenAI集成**
   - 输入：OpenAI API格式的请求
   - 预期：成功调用OpenAI API
   - 验证：响应格式符合OpenAI API规范

3. **渠道切换**
   - 输入：配置多个渠道的Proxy-Key
   - 预期：根据优先级选择渠道
   - 验证：故障转移机制正常

### 2.2 WebSocket协议集成测试

#### 2.2.1 WebSocket握手测试
**测试用例**：
1. **正常握手**
   - 输入：标准WebSocket握手请求
   - 预期：握手成功，连接建立
   - 验证：API-Key在握手阶段正确替换

2. **握手失败**
   - 输入：无效的握手请求
   - 预期：握手失败，返回错误
   - 验证：错误信息正确

#### 2.2.2 WebSocket数据传输测试
**测试用例**：
1. **数据帧转发**
   - 输入：WebSocket数据帧
   - 预期：数据帧完整转发
   - 验证：数据内容不被修改

2. **连接保持**
   - 输入：长时间WebSocket连接
   - 预期：连接保持稳定
   - 验证：心跳机制正常

### 2.3 端到端业务流程测试

#### 2.3.1 完整业务流程测试
**测试场景**：用户从注册到使用API的完整流程

**测试步骤**：
1. 用户注册 → 分配Proxy-Key
2. 配置渠道映射 → 设置渠道优先级
3. 发起API请求 → 验证代理转发
4. 查看使用统计 → 验证统计数据

**验证点**：
- 每个步骤都能正常完成
- 数据在各个模块间正确传递
- 错误处理机制正常工作

#### 2.3.2 异常场景测试
**测试用例**：
1. **渠道服务不可用**
   - 场景：目标渠道API服务中断
   - 预期：返回明确的错误信息
   - 验证：错误处理和日志记录

2. **网络超时**
   - 场景：网络延迟导致请求超时
   - 预期：在配置的超时时间内返回超时错误
   - 验证：超时机制正常工作

### 2.4 配置加载与热重载专项测试
**测试目标**：验证配置文件加载和热重载功能的正确性和稳定性。

**测试前置条件**：
- 代理服务已部署并正在运行。
- 配置文件路径已知，并可被测试脚本访问和修改。
- 需求文档中定义的 `config_reload_interval` 已配置。

**测试用例**：
1. **正常加载测试**
   - 测试方法：使用格式完全正确的配置文件启动服务。
   - 输入：包含有效用户、渠道和映射关系的配置文件。
   - 预期：服务正常启动，无错误日志。通过API调用，验证配置文件中的用户可正常使用代理。
   - 验证：服务日志无异常，API调用成功。

2. **异常加载测试（格式错误）**
   - 测试方法：使用YAML/JSON等格式错误的配置文件尝试启动服务。
   - 输入：一个语法错误的配置文件（例如，缩进错误、缺少引号等）。
   - 预期：服务启动失败，并在启动日志中打印出明确的、可定位的配置文件解析错误信息。
   - 验证：服务未成功运行，日志中包含解析错误的详细信息。

3. **异常加载测试（文件不存在）**
   - 测试方法：在未放置配置文件的情况下尝试启动服务。
   - 输入：无配置文件。
   - 预期：服务启动失败，并报告配置文件缺失的错误。
   - 验证：服务未成功运行，日志中包含文件找不到的错误信息。

4. **热重载测试（新增用户）**
   - 测试方法：在服务运行时，动态向配置文件中添加一个新用户。
   - 输入：在`users`配置下增加一个新用户条目。
   - 预期：等待超过 `config_reload_interval` 后，使用新用户的Proxy-Key可以成功调用API。
   - 验证：新用户的API调用成功，旧用户不受影响。

5. **热重载测试（修改渠道API-Key）**
   - 测试方法：在服务运行时，动态修改配置文件中某个渠道的`api_key`。
   - 输入：修改`channels`配置下一个渠道的`api_key`为一个新的有效值。
   - 预期：等待热重载周期后，通过该渠道的请求会使用新的`api_key`并成功转发。
   - 验证：API调用成功，可以通过目标渠道的后台日志确认收到的请求使用了新API Key。

6. **热重载测试（禁用用户）**
   - 测试方法：在服务运行时，将配置文件中某个用户的`status`从`active`修改为`disabled`。
   - 输入：修改`users`配置下某个用户的状态。
   - 预期：等待热重载周期后，该用户的所有API请求都应被拒绝。
   - 验证：使用该用户的Proxy-Key调用API会返回认证失败的错误。

## 3. 兼容性测试需求

### 3.1 API兼容性测试

#### 3.1.1 渠道API兼容性
**测试目标**：验证与各渠道API的兼容性

**测试用例**：
1. **阿里云百炼API兼容性**
   - 测试所有支持的百炼API接口
   - 验证请求格式和响应格式
   - 检查错误处理机制

2. **OpenAI API兼容性**
   - 测试OpenAI API的各个版本
   - 验证SDK兼容性
   - 检查参数传递正确性

#### 3.1.2 SDK兼容性测试
**测试用例**：
1. **官方SDK测试**
   - 使用各渠道官方SDK进行测试
   - 验证SDK调用的正确性

2. **第三方SDK测试**
   - 测试常用的第三方SDK
   - 验证兼容性和稳定性

### 3.2 协议兼容性测试

#### 3.2.1 HTTP版本兼容性
**测试用例**：
- HTTP/1.1兼容性测试
- HTTP/2兼容性测试（如果支持）

#### 3.2.2 WebSocket版本兼容性
**测试用例**：
- WebSocket协议版本兼容性
- 不同浏览器WebSocket实现兼容性

## 4. 回归测试需求

### 4.1 功能回归测试

#### 4.1.1 核心功能回归测试
**测试范围**：
- 代理转发功能
- API-Key替换功能
- 用户认证功能
- 统计功能

**测试频率**：每次代码提交后执行

#### 4.1.2 集成功能回归测试
**测试范围**：
- 多渠道集成
- 协议支持
- 错误处理

**测试频率**：每次发布前执行

## 5. 测试数据管理

### 5.1 测试数据准备

#### 5.1.1 用户测试数据
```yaml
# 测试用户配置
test_users:
  test_user_1:
    name: "测试用户1"
    department: "测试部门"
    proxy_key: "pk_test_user1_12345"
    status: "active"
    channels: ["test_channel_1", "test_channel_2"]
    
  test_user_2:
    name: "测试用户2"
    department: "测试部门"
    proxy_key: "pk_test_user2_67890"
    status: "disabled"
    channels: ["test_channel_1"]
```

#### 5.1.2 渠道测试数据
```yaml
# 测试渠道配置
test_channels:
  test_channel_1:
    name: "测试渠道1"
    api_key: "sk_test_channel1_abcdef"
    base_url: "https://api.test-channel1.com"
    status: "active"
    timeout: 30
    
  test_channel_2:
    name: "测试渠道2"
    api_key: "sk_test_channel2_ghijkl"
    base_url: "https://api.test-channel2.com"
    status: "active"
    timeout: 30
```

### 5.2 测试环境管理

#### 5.2.1 环境配置
- **开发环境**：使用Mock数据，快速反馈
- **测试环境**：使用真实测试数据，完整功能测试
- **预生产环境**：使用生产级数据，性能和稳定性测试

#### 5.2.2 数据隔离
- 测试数据与生产数据完全隔离
- 不同测试环境间数据隔离
- 测试数据定期清理和重置

## 6. 测试工具和技术

### 6.1 测试工具选型

#### 6.1.1 集成测试工具
- **Python OpenAI SDK**：用于OpenAI兼容API测试
- **Python DashScope SDK**：用于阿里云百炼API测试
- **WebSocket客户端库**：用于WebSocket测试
- **pytest**：用于测试框架和断言


---

**文档版本**：v1.0  
**创建日期**：2025年7月9日  
**最后更新**：2025年7月9日 11:45  
**文档状态**：已审核 